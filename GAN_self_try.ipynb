{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZsLNiofDtkCWakqAlANxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumaiyaZohaRODELA/GAN_selfstudy/blob/main/GAN_self_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8yjNWLSH84ZH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "OhzEL16D-Ik2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Defining Image Transformations"
      ],
      "metadata": {
        "id": "T_YwGj-l-Rri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a basic transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "H5WnbbTL-TSV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Loading the CIFAR-10 Dataset\n",
        "\n",
        "The CIFAR-10 dataset is loaded with predefined transformations. A DataLoader is created to process the dataset in mini-batches of 32 images, shuffled for randomness.\n"
      ],
      "metadata": {
        "id": "GLZ3hyru-dHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data',\\\n",
        "              train=True, download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, \\\n",
        "                                batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vPebytv-eK7",
        "outputId": "25b52dbc-3e84-4a24-c836-2192cba0bcb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 53.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Defining GAN Hyperparameters\n",
        "Key hyperparameters are defined:\n",
        "\n",
        "latent_dim – Dimensionality of the noise vector.\n",
        "lr – Learning rate of the optimizer.\n",
        "beta1, beta2 – Adam optimizer coefficients.\n",
        "num_epochs – Total training iterations."
      ],
      "metadata": {
        "id": "EW_nRusJ-vEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "RJWBHMGa-r7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Building the Generator\n",
        "The generator takes a random latent vector (z) as input and transforms it into an image through convolutional, batch normalization, and upsampling layers. The final output uses Tanh activation to ensure pixel values are within the expected range."
      ],
      "metadata": {
        "id": "Fg_zDry6-5se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img"
      ],
      "metadata": {
        "id": "2GiVcGEc-6rM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Building the Discriminator\n",
        "The discriminator is a binary classifier that distinguishes between real and generated images. It consists of convolutional layers, batch normalization, dropout, and LeakyReLU activation to improve learning stability."
      ],
      "metadata": {
        "id": "jJVs5bXl_Evu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.ZeroPad2d((0, 1, 0, 1)),\n",
        "        nn.BatchNorm2d(64, momentum=0.82),\n",
        "        nn.LeakyReLU(0.25),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(128, momentum=0.82),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(256, momentum=0.8),\n",
        "        nn.LeakyReLU(0.25),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256 * 5 * 5, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "6EofgUtQ_F-y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Initializing GAN Components\n",
        "Generator and Discriminator are initialized on the available device (GPU or CPU).\n",
        "Binary Cross-Entropy (BCE) Loss is chosen as the loss function.\n",
        "Adam optimizers are defined separately for the generator and discriminator with specified learning rates and betas.\n",
        "\n"
      ],
      "metadata": {
        "id": "I7srQy_u_NPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator and discriminator\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "# Loss function\n",
        "adversarial_loss = nn.BCELoss()\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters()\\\n",
        "                         , lr=lr, betas=(beta1, beta2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters()\\\n",
        "                         , lr=lr, betas=(beta1, beta2))"
      ],
      "metadata": {
        "id": "SxnWNiWf_OPn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Training the GAN\n",
        ".The discriminator is trained to differentiate between real and fake images.\n",
        ".The generator is trained to produce realistic images that fool the discriminator.\n",
        ".The loss is backpropagated using Adam optimizers, and the model updates its parameters.\n",
        ".Progress tracking: Loss values for both networks are printed, and generated images are displayed every 10 epochs for visual inspection."
      ],
      "metadata": {
        "id": "QYenqGmJ_Yec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "       # Convert list to tensor\n",
        "        real_images = batch[0].to(device)\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(real_images.size(0), 1, device=device)\n",
        "        fake = torch.zeros(real_images.size(0), 1, device=device)\n",
        "       o # Configure input\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "        # Generate a batch of images\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Measure discriminator's ability\n",
        "        # to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator\\\n",
        "                                     (real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator\\\n",
        "                                     (fake_images.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        # Generate a batch of images\n",
        "        gen_images = generator(z)\n",
        "        # Adversarial loss\n",
        "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        # ---------------------\n",
        "        #  Progress Monitoring\n",
        "        # ---------------------\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
        "                        Batch {i+1}/{len(dataloader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "    # Save generated images for every epoch\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, latent_dim, device=device)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = torchvision.utils.make_grid(generated,\\\n",
        "                                        nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "ks94y0EK_fni",
        "outputId": "a9f3afd1-dd0b-4e26-b74e-90103247a139"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    o # Configure input\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "       # Convert list to tensor\n",
        "        real_images = batch[0].to(device)\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(real_images.size(0), 1, device=device)\n",
        "        fake = torch.zeros(real_images.size(0), 1, device=device)\n",
        "        # Configure input\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "        # Generate a batch of images\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Measure discriminator's ability\n",
        "        # to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator\\\n",
        "                                     (real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator\\\n",
        "                                     (fake_images.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        # Generate a batch of images\n",
        "        gen_images = generator(z)\n",
        "        # Adversarial loss\n",
        "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        # ---------------------\n",
        "        #  Progress Monitoring\n",
        "        # ---------------------\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
        "                        Batch {i+1}/{len(dataloader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "    # Save generated images for every epoch\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, latent_dim, device=device)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = torchvision.utils.make_grid(generated,\\\n",
        "                                        nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "xXPPj6DCG6I5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}