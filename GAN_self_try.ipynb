{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxB2pfkY7lCe6LGMLOSysT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumaiyaZohaRODELA/GAN_selfstudy/blob/main/GAN_self_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8yjNWLSH84ZH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "OhzEL16D-Ik2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Defining Image Transformations"
      ],
      "metadata": {
        "id": "T_YwGj-l-Rri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a basic transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "H5WnbbTL-TSV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Loading the CIFAR-10 Dataset\n",
        "\n",
        "The CIFAR-10 dataset is loaded with predefined transformations. A DataLoader is created to process the dataset in mini-batches of 32 images, shuffled for randomness.\n"
      ],
      "metadata": {
        "id": "GLZ3hyru-dHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data',\\\n",
        "              train=True, download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, \\\n",
        "                                batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vPebytv-eK7",
        "outputId": "25b52dbc-3e84-4a24-c836-2192cba0bcb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 53.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Defining GAN Hyperparameters\n",
        "Key hyperparameters are defined:\n",
        "\n",
        "latent_dim – Dimensionality of the noise vector.\n",
        "lr – Learning rate of the optimizer.\n",
        "beta1, beta2 – Adam optimizer coefficients.\n",
        "num_epochs – Total training iterations."
      ],
      "metadata": {
        "id": "EW_nRusJ-vEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "RJWBHMGa-r7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Building the Generator\n",
        "The generator takes a random latent vector (z) as input and transforms it into an image through convolutional, batch normalization, and upsampling layers. The final output uses Tanh activation to ensure pixel values are within the expected range."
      ],
      "metadata": {
        "id": "Fg_zDry6-5se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img"
      ],
      "metadata": {
        "id": "2GiVcGEc-6rM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Building the Discriminator\n",
        "The discriminator is a binary classifier that distinguishes between real and generated images. It consists of convolutional layers, batch normalization, dropout, and LeakyReLU activation to improve learning stability."
      ],
      "metadata": {
        "id": "jJVs5bXl_Evu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.ZeroPad2d((0, 1, 0, 1)),\n",
        "        nn.BatchNorm2d(64, momentum=0.82),\n",
        "        nn.LeakyReLU(0.25),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(128, momentum=0.82),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(256, momentum=0.8),\n",
        "        nn.LeakyReLU(0.25),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256 * 5 * 5, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "6EofgUtQ_F-y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Initializing GAN Components\n",
        "Generator and Discriminator are initialized on the available device (GPU or CPU).\n",
        "Binary Cross-Entropy (BCE) Loss is chosen as the loss function.\n",
        "Adam optimizers are defined separately for the generator and discriminator with specified learning rates and betas.\n",
        "\n"
      ],
      "metadata": {
        "id": "I7srQy_u_NPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator and discriminator\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "# Loss function\n",
        "adversarial_loss = nn.BCELoss()\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters()\\\n",
        "                         , lr=lr, betas=(beta1, beta2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters()\\\n",
        "                         , lr=lr, betas=(beta1, beta2))"
      ],
      "metadata": {
        "id": "SxnWNiWf_OPn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Training the GAN\n",
        ".The discriminator is trained to differentiate between real and fake images.\n",
        ".The generator is trained to produce realistic images that fool the discriminator.\n",
        ".The loss is backpropagated using Adam optimizers, and the model updates its parameters.\n",
        ".Progress tracking: Loss values for both networks are printed, and generated images are displayed every 10 epochs for visual inspection."
      ],
      "metadata": {
        "id": "QYenqGmJ_Yec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "       # Convert list to tensor\n",
        "        real_images = batch[0].to(device)\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(real_images.size(0), 1, device=device)\n",
        "        fake = torch.zeros(real_images.size(0), 1, device=device)\n",
        "        # Configure input\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "        # Generate a batch of images\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Measure discriminator's ability\n",
        "        # to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator\\\n",
        "                                     (real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator\\\n",
        "                                     (fake_images.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        # Generate a batch of images\n",
        "        gen_images = generator(z)\n",
        "        # Adversarial loss\n",
        "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        # ---------------------\n",
        "        #  Progress Monitoring\n",
        "        # ---------------------\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
        "                        Batch {i+1}/{len(dataloader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "    # Save generated images for every epoch\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, latent_dim, device=device)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = torchvision.utils.make_grid(generated,\\\n",
        "                                        nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks94y0EK_fni",
        "outputId": "92045486-9ce7-4a37-da21-7fb3f1043714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]                        Batch 100/1563 Discriminator Loss: 0.5495 Generator Loss: 1.5477\n",
            "Epoch [1/10]                        Batch 200/1563 Discriminator Loss: 0.8036 Generator Loss: 0.8763\n",
            "Epoch [1/10]                        Batch 300/1563 Discriminator Loss: 0.6113 Generator Loss: 1.2012\n",
            "Epoch [1/10]                        Batch 400/1563 Discriminator Loss: 0.8545 Generator Loss: 0.8410\n",
            "Epoch [1/10]                        Batch 500/1563 Discriminator Loss: 0.5737 Generator Loss: 1.2407\n",
            "Epoch [1/10]                        Batch 600/1563 Discriminator Loss: 0.5622 Generator Loss: 1.0217\n",
            "Epoch [1/10]                        Batch 700/1563 Discriminator Loss: 0.6917 Generator Loss: 1.0435\n",
            "Epoch [1/10]                        Batch 800/1563 Discriminator Loss: 0.7806 Generator Loss: 0.9141\n",
            "Epoch [1/10]                        Batch 900/1563 Discriminator Loss: 0.5485 Generator Loss: 1.0855\n",
            "Epoch [1/10]                        Batch 1000/1563 Discriminator Loss: 0.6742 Generator Loss: 1.4930\n",
            "Epoch [1/10]                        Batch 1100/1563 Discriminator Loss: 0.7052 Generator Loss: 1.0680\n",
            "Epoch [1/10]                        Batch 1200/1563 Discriminator Loss: 0.7140 Generator Loss: 0.9817\n",
            "Epoch [1/10]                        Batch 1300/1563 Discriminator Loss: 0.7285 Generator Loss: 0.9200\n",
            "Epoch [1/10]                        Batch 1400/1563 Discriminator Loss: 0.5787 Generator Loss: 0.9784\n",
            "Epoch [1/10]                        Batch 1500/1563 Discriminator Loss: 0.7683 Generator Loss: 0.6913\n",
            "Epoch [2/10]                        Batch 100/1563 Discriminator Loss: 0.6001 Generator Loss: 0.8533\n",
            "Epoch [2/10]                        Batch 200/1563 Discriminator Loss: 0.7490 Generator Loss: 0.9097\n",
            "Epoch [2/10]                        Batch 300/1563 Discriminator Loss: 0.6821 Generator Loss: 0.8228\n",
            "Epoch [2/10]                        Batch 400/1563 Discriminator Loss: 0.6561 Generator Loss: 0.8925\n",
            "Epoch [2/10]                        Batch 500/1563 Discriminator Loss: 0.5510 Generator Loss: 1.4131\n",
            "Epoch [2/10]                        Batch 600/1563 Discriminator Loss: 0.7896 Generator Loss: 0.8893\n",
            "Epoch [2/10]                        Batch 700/1563 Discriminator Loss: 0.5851 Generator Loss: 0.9102\n",
            "Epoch [2/10]                        Batch 800/1563 Discriminator Loss: 0.9220 Generator Loss: 0.6713\n",
            "Epoch [2/10]                        Batch 900/1563 Discriminator Loss: 0.9864 Generator Loss: 0.8228\n",
            "Epoch [2/10]                        Batch 1000/1563 Discriminator Loss: 0.6802 Generator Loss: 1.0722\n",
            "Epoch [2/10]                        Batch 1100/1563 Discriminator Loss: 0.5866 Generator Loss: 0.9252\n",
            "Epoch [2/10]                        Batch 1200/1563 Discriminator Loss: 0.7764 Generator Loss: 0.8371\n",
            "Epoch [2/10]                        Batch 1300/1563 Discriminator Loss: 0.5709 Generator Loss: 1.0132\n",
            "Epoch [2/10]                        Batch 1400/1563 Discriminator Loss: 0.6759 Generator Loss: 0.9872\n",
            "Epoch [2/10]                        Batch 1500/1563 Discriminator Loss: 0.5796 Generator Loss: 1.1274\n",
            "Epoch [3/10]                        Batch 100/1563 Discriminator Loss: 0.6654 Generator Loss: 1.0198\n",
            "Epoch [3/10]                        Batch 200/1563 Discriminator Loss: 0.6148 Generator Loss: 1.1750\n",
            "Epoch [3/10]                        Batch 300/1563 Discriminator Loss: 0.5758 Generator Loss: 1.2788\n",
            "Epoch [3/10]                        Batch 400/1563 Discriminator Loss: 0.5510 Generator Loss: 1.0811\n",
            "Epoch [3/10]                        Batch 500/1563 Discriminator Loss: 0.6275 Generator Loss: 1.3008\n",
            "Epoch [3/10]                        Batch 600/1563 Discriminator Loss: 0.6187 Generator Loss: 0.9642\n",
            "Epoch [3/10]                        Batch 700/1563 Discriminator Loss: 0.5528 Generator Loss: 1.1669\n",
            "Epoch [3/10]                        Batch 800/1563 Discriminator Loss: 0.5646 Generator Loss: 0.9319\n",
            "Epoch [3/10]                        Batch 900/1563 Discriminator Loss: 0.6243 Generator Loss: 0.8005\n",
            "Epoch [3/10]                        Batch 1000/1563 Discriminator Loss: 0.5828 Generator Loss: 1.0580\n",
            "Epoch [3/10]                        Batch 1100/1563 Discriminator Loss: 0.7955 Generator Loss: 0.8181\n",
            "Epoch [3/10]                        Batch 1200/1563 Discriminator Loss: 0.4297 Generator Loss: 1.6607\n",
            "Epoch [3/10]                        Batch 1300/1563 Discriminator Loss: 0.5850 Generator Loss: 0.7441\n",
            "Epoch [3/10]                        Batch 1400/1563 Discriminator Loss: 0.7741 Generator Loss: 0.7628\n",
            "Epoch [3/10]                        Batch 1500/1563 Discriminator Loss: 0.6182 Generator Loss: 1.1043\n",
            "Epoch [4/10]                        Batch 100/1563 Discriminator Loss: 0.7645 Generator Loss: 0.8195\n",
            "Epoch [4/10]                        Batch 200/1563 Discriminator Loss: 0.5423 Generator Loss: 0.9048\n",
            "Epoch [4/10]                        Batch 300/1563 Discriminator Loss: 0.5776 Generator Loss: 1.3236\n",
            "Epoch [4/10]                        Batch 400/1563 Discriminator Loss: 0.6575 Generator Loss: 0.8681\n",
            "Epoch [4/10]                        Batch 500/1563 Discriminator Loss: 0.5461 Generator Loss: 1.2281\n",
            "Epoch [4/10]                        Batch 600/1563 Discriminator Loss: 0.5515 Generator Loss: 0.8448\n",
            "Epoch [4/10]                        Batch 700/1563 Discriminator Loss: 0.7874 Generator Loss: 1.1791\n",
            "Epoch [4/10]                        Batch 800/1563 Discriminator Loss: 0.5859 Generator Loss: 1.2838\n",
            "Epoch [4/10]                        Batch 900/1563 Discriminator Loss: 0.5533 Generator Loss: 1.1488\n",
            "Epoch [4/10]                        Batch 1000/1563 Discriminator Loss: 0.7893 Generator Loss: 0.7621\n",
            "Epoch [4/10]                        Batch 1100/1563 Discriminator Loss: 0.6376 Generator Loss: 0.8597\n",
            "Epoch [4/10]                        Batch 1200/1563 Discriminator Loss: 0.6048 Generator Loss: 1.2382\n",
            "Epoch [4/10]                        Batch 1300/1563 Discriminator Loss: 0.6286 Generator Loss: 1.0968\n",
            "Epoch [4/10]                        Batch 1400/1563 Discriminator Loss: 0.4536 Generator Loss: 1.1608\n",
            "Epoch [4/10]                        Batch 1500/1563 Discriminator Loss: 0.4502 Generator Loss: 1.3191\n",
            "Epoch [5/10]                        Batch 100/1563 Discriminator Loss: 0.4367 Generator Loss: 1.1131\n",
            "Epoch [5/10]                        Batch 200/1563 Discriminator Loss: 0.4377 Generator Loss: 1.1618\n",
            "Epoch [5/10]                        Batch 300/1563 Discriminator Loss: 0.5647 Generator Loss: 1.1850\n",
            "Epoch [5/10]                        Batch 400/1563 Discriminator Loss: 0.5835 Generator Loss: 0.7762\n",
            "Epoch [5/10]                        Batch 500/1563 Discriminator Loss: 0.5308 Generator Loss: 1.1723\n",
            "Epoch [5/10]                        Batch 600/1563 Discriminator Loss: 0.5629 Generator Loss: 1.4239\n",
            "Epoch [5/10]                        Batch 700/1563 Discriminator Loss: 0.4730 Generator Loss: 1.2657\n",
            "Epoch [5/10]                        Batch 800/1563 Discriminator Loss: 0.7499 Generator Loss: 0.8737\n",
            "Epoch [5/10]                        Batch 900/1563 Discriminator Loss: 0.7306 Generator Loss: 1.0781\n",
            "Epoch [5/10]                        Batch 1000/1563 Discriminator Loss: 0.7053 Generator Loss: 1.0924\n",
            "Epoch [5/10]                        Batch 1100/1563 Discriminator Loss: 0.6990 Generator Loss: 0.9021\n",
            "Epoch [5/10]                        Batch 1200/1563 Discriminator Loss: 0.6035 Generator Loss: 1.2184\n",
            "Epoch [5/10]                        Batch 1300/1563 Discriminator Loss: 0.6907 Generator Loss: 0.8353\n",
            "Epoch [5/10]                        Batch 1400/1563 Discriminator Loss: 0.6328 Generator Loss: 0.7172\n",
            "Epoch [5/10]                        Batch 1500/1563 Discriminator Loss: 0.6663 Generator Loss: 0.9588\n",
            "Epoch [6/10]                        Batch 100/1563 Discriminator Loss: 0.7747 Generator Loss: 0.8991\n",
            "Epoch [6/10]                        Batch 200/1563 Discriminator Loss: 0.5760 Generator Loss: 1.1167\n",
            "Epoch [6/10]                        Batch 300/1563 Discriminator Loss: 0.5913 Generator Loss: 0.7891\n",
            "Epoch [6/10]                        Batch 400/1563 Discriminator Loss: 0.5982 Generator Loss: 1.4084\n",
            "Epoch [6/10]                        Batch 500/1563 Discriminator Loss: 0.6105 Generator Loss: 1.3512\n",
            "Epoch [6/10]                        Batch 600/1563 Discriminator Loss: 0.7123 Generator Loss: 1.0614\n",
            "Epoch [6/10]                        Batch 700/1563 Discriminator Loss: 0.6082 Generator Loss: 1.0459\n",
            "Epoch [6/10]                        Batch 800/1563 Discriminator Loss: 0.6083 Generator Loss: 1.4437\n",
            "Epoch [6/10]                        Batch 900/1563 Discriminator Loss: 0.5815 Generator Loss: 1.2788\n",
            "Epoch [6/10]                        Batch 1000/1563 Discriminator Loss: 1.0730 Generator Loss: 1.3078\n",
            "Epoch [6/10]                        Batch 1100/1563 Discriminator Loss: 0.5532 Generator Loss: 1.1997\n",
            "Epoch [6/10]                        Batch 1200/1563 Discriminator Loss: 0.8344 Generator Loss: 0.7464\n",
            "Epoch [6/10]                        Batch 1300/1563 Discriminator Loss: 0.7077 Generator Loss: 1.1141\n",
            "Epoch [6/10]                        Batch 1400/1563 Discriminator Loss: 0.6933 Generator Loss: 0.9938\n",
            "Epoch [6/10]                        Batch 1500/1563 Discriminator Loss: 0.7924 Generator Loss: 0.8316\n",
            "Epoch [7/10]                        Batch 100/1563 Discriminator Loss: 0.5886 Generator Loss: 1.6822\n",
            "Epoch [7/10]                        Batch 200/1563 Discriminator Loss: 0.4743 Generator Loss: 1.0140\n",
            "Epoch [7/10]                        Batch 300/1563 Discriminator Loss: 0.5840 Generator Loss: 0.9587\n",
            "Epoch [7/10]                        Batch 400/1563 Discriminator Loss: 0.7154 Generator Loss: 0.9760\n",
            "Epoch [7/10]                        Batch 500/1563 Discriminator Loss: 0.5521 Generator Loss: 1.5168\n",
            "Epoch [7/10]                        Batch 600/1563 Discriminator Loss: 0.5277 Generator Loss: 1.1573\n",
            "Epoch [7/10]                        Batch 700/1563 Discriminator Loss: 0.5675 Generator Loss: 1.1791\n",
            "Epoch [7/10]                        Batch 800/1563 Discriminator Loss: 0.3567 Generator Loss: 1.7156\n",
            "Epoch [7/10]                        Batch 900/1563 Discriminator Loss: 0.5460 Generator Loss: 1.3088\n",
            "Epoch [7/10]                        Batch 1000/1563 Discriminator Loss: 0.5573 Generator Loss: 1.1311\n",
            "Epoch [7/10]                        Batch 1100/1563 Discriminator Loss: 0.9045 Generator Loss: 0.6427\n",
            "Epoch [7/10]                        Batch 1200/1563 Discriminator Loss: 0.5489 Generator Loss: 1.3369\n",
            "Epoch [7/10]                        Batch 1300/1563 Discriminator Loss: 0.3953 Generator Loss: 1.5195\n",
            "Epoch [7/10]                        Batch 1400/1563 Discriminator Loss: 0.4365 Generator Loss: 1.5837\n",
            "Epoch [7/10]                        Batch 1500/1563 Discriminator Loss: 0.4971 Generator Loss: 1.4480\n",
            "Epoch [8/10]                        Batch 100/1563 Discriminator Loss: 0.5990 Generator Loss: 0.6548\n",
            "Epoch [8/10]                        Batch 200/1563 Discriminator Loss: 0.4333 Generator Loss: 0.8818\n",
            "Epoch [8/10]                        Batch 300/1563 Discriminator Loss: 0.5839 Generator Loss: 1.6767\n",
            "Epoch [8/10]                        Batch 400/1563 Discriminator Loss: 0.5587 Generator Loss: 0.8946\n",
            "Epoch [8/10]                        Batch 500/1563 Discriminator Loss: 0.4018 Generator Loss: 1.9121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "       # Convert list to tensor\n",
        "        real_images = batch[0].to(device)\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(real_images.size(0), 1, device=device)\n",
        "        fake = torch.zeros(real_images.size(0), 1, device=device)\n",
        "        # Configure input\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "        # Generate a batch of images\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Measure discriminator's ability\n",
        "        # to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator\\\n",
        "                                     (real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator\\\n",
        "                                     (fake_images.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        # Generate a batch of images\n",
        "        gen_images = generator(z)\n",
        "        # Adversarial loss\n",
        "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        # ---------------------\n",
        "        #  Progress Monitoring\n",
        "        # ---------------------\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
        "                        Batch {i+1}/{len(dataloader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "    # Save generated images for every epoch\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, latent_dim, device=device)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = torchvision.utils.make_grid(generated,\\\n",
        "                                        nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "xXPPj6DCG6I5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}